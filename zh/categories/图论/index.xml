<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>图论 on 绯想天</title><link>https://www.flandre.love/zh/categories/%E5%9B%BE%E8%AE%BA/</link><description>Recent content in 图论 on 绯想天</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Copyright © 2020 - 2023 Fei Pan</copyright><lastBuildDate>Wed, 18 Jan 2023 15:24:00 +0800</lastBuildDate><atom:link href="https://www.flandre.love/zh/categories/%E5%9B%BE%E8%AE%BA/index.xml" rel="self" type="application/rss+xml"/><item><title>强连通分量和点双连通分量</title><link>https://www.flandre.love/zh/posts/connected_component/</link><pubDate>Wed, 18 Jan 2023 15:24:00 +0800</pubDate><guid>https://www.flandre.love/zh/posts/connected_component/</guid><description>&lt;p>强连通分量和点双连通分量是图论中常见的两个概念。算法竞赛中，我们处理它们时都要使用 Tarjan 算法，因而这二者常常被混淆。强连通分量常常被缩点代称，而点双连通分量则常被割点代称。事实上，缩点和割点并不是一组对应的概念；缩点在点双连通分量中对应的概念是圆方树，割点在强连通分量中对应的概念是割边（桥）。因此，我们要么说“强连通分量和点双连通分量”，要么说“缩点和圆方树”，要么说“割边和割点”，但是不要说“缩点和割点”。人们常将缩点和割点并称的原因可能是洛谷，其关于构造强连通分量和点双连通分量的模板题的名称分别为“缩点”和“割点”，具有很强的误导性。尤其是“缩点”和“割点”都含有“点”字，容易让初学者以为它们是对应的概念，看不透二者的真正关系。&lt;/p>
&lt;p>那么，强连通分量和点双连通分量的真正关系是什么呢？或者说，怎样才能最好地理解它们的相似性和差异性呢？&lt;/p>
&lt;p>割边和割点的关系。强连通分量是割边分隔出的点集，点双连通分量是割点分割出的点集（特别地，割点本身同时属于它四周的点双连通分量）。因此它们都可以使用 Tarjan 算法处理。在 DFS 树上，一条边 $E$ 是割边当且仅当其儿子的子树中没有指向 $E$ 的祖先（注意这里不是子树外而是祖先，因为有向图的 DFS 树形态特别）的返祖边，一个结点 $V$ 是割点当且仅当其&lt;strong>某个&lt;/strong>儿子的子树中没有指向 $V$ 的祖先的返祖边。删去强连通分量中的任何边得到的生成子图仍然连通（弱连通），删去点双连通分量中的任何结点得到的导出子图仍然连通。&lt;/p>
&lt;p>有向图和无向图的关系。强连通分量在有向图中定义，点双连通分量在无向图中定义。“任意两个结点都能够互相到达的极大子图”这一定义不能够在无向图中定义强连通分量，因为这实际上指的是连通块；但我们可以用强连通分量的另一个定义“割边分割出的点集”在无向图中定义一个与强连通分量相似的概念，即边双连通分量。因此，“割边分割出的点集”是最适合强连通分量和边双连通分量的定义，它同时适用于有向图和无向图，而强连通分量“任意两个结点都能够互相到达的极大子图”和边双连通分量“删去任意边后任意两个结点仍然连通的极大子图”这两个常见定义则只适用于有向图或无向图。&lt;/p>
&lt;p>对于有向图，我们发现，一个节点 $v$ 的父边是割边，当且仅当从 $v$ 出发无法离开 $v$ 的子树；一个节点 $v$ 是割点，当且仅当从 $v$ 出发，且不经过从 $v$ 出发的返祖边，无法离开 $v$ 的子树。&lt;/p>
&lt;p>关于为什么求强连通分量可以写 &lt;code>low[node]=min(low[node],low[to])&lt;/code> 而求点双连通分量却只能写 &lt;code>low[node]=min(low[node],dfn[node]&lt;/code> 的原因，想必读者也已经懂了。当然 &lt;code>low[node]=min(low[node],low[to])&lt;/code> 也不是一定就不能用于求割点，比如下面的代码就是可行的。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-cpp" data-lang="cpp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#a6e22e">dfs&lt;/span> (&lt;span style="color:#66d9ef">int&lt;/span> node) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dfn[node] &lt;span style="color:#f92672">=&lt;/span> low[node] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#f92672">++&lt;/span>ind;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> (&lt;span style="color:#66d9ef">int&lt;/span> i &lt;span style="color:#f92672">=&lt;/span> head[node]; i; i &lt;span style="color:#f92672">=&lt;/span> edge[i].next) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (&lt;span style="color:#f92672">!&lt;/span>dfn[edge[i].to]) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dfs(edge[i].to);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (low[edge[i].to] &lt;span style="color:#f92672">==&lt;/span> dfn[node]) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> is_cut[node] &lt;span style="color:#f92672">=&lt;/span> true;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> (&lt;span style="color:#66d9ef">int&lt;/span> i &lt;span style="color:#f92672">=&lt;/span> head[node]; i; i &lt;span style="color:#f92672">=&lt;/span> edge[i].next) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> low[node] &lt;span style="color:#f92672">=&lt;/span> std&lt;span style="color:#f92672">::&lt;/span>min(low[node], low[edge[i].to]);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>凸包的闵可夫斯基和</title><link>https://www.flandre.love/zh/posts/sum_of_convex/</link><pubDate>Thu, 25 Aug 2022 09:57:07 +0800</pubDate><guid>https://www.flandre.love/zh/posts/sum_of_convex/</guid><description>&lt;p>对于两个点集 $A$ 与 $B$，它们的闵可夫斯基和就是 $A + B = {\mathbf a + \mathbf b \rvert \mathbf a \in A, \mathbf b \in B}$。本文只讨论 $A$ 和 $B$ 都是凸包的情况。&lt;/p>
&lt;h2 id="符号和约定">符号和约定&lt;/h2>
&lt;p>$|A|$ 表示凸包 $A$ 的顶点个数，$A_i$ 表示凸包的第 $i$ 个顶点，并且下标是循环的（即 $A_i$ 与 $A_{i+|A|}$ 指同一顶点）。&lt;/p>
&lt;h2 id="结论和实现">结论和实现&lt;/h2>
&lt;p>将 $\vec{A_iA_{i+1}}(i \in [1, |A|])$ 和 $\vec{B_iB_{i+1}}(i \in [1, |B|])$ 这 $|A| + |B|$ 条向量极角排序，并合并其中的同向边，顺次连接，即可得到 $A+B$ 的轮廓。&lt;/p>
&lt;p>实现上，我们不会采用比较斜率的方式来极角排序，因为那样涉及浮点运算；我们可以用向量的叉积作为排序的比较器，实现 $O(n\log n)$ 的算法。进一步地，由于 $\vec{A_iA_{i+1}}(i \in [1, |A|])$ 和 $\vec{B_iB_{i+1}}(i \in [1, |B|])$ 各自原本就是按极角有序的，我们还可以使用类似归并排序的方式 $O(n)$ 地合并它们。&lt;/p>
&lt;h2 id="凸包的闵可夫斯基和在算法竞赛中的应用">凸包的闵可夫斯基和在算法竞赛中的应用&lt;/h2>
&lt;p>利用凸包求和，我们可以快速地进行最值卷积，即以 $O(|F|+|G|)$ 的时间复杂度求出 $\forall k, P_k = \max\limits_{i+j=k} F_i + G_j$ 和 $\forall k, Q_k = \min\limits_{i+j=k} F_i + G_j$；配合分治式合并可以在 $O(n\log n)$ 的时间内完成一系列大小总和不超过 $n$ 的数列的合并。Splay 启发式合并也可以做到 $O(n\log n)$ 的复杂度，并且相比分治式合并维护树上 DP $O(n^2)$ 的复杂度（这和暴力复杂度相同），它却可以 $O(n\log n)$ 维护树上 DP（因为 Splay 启发式合并的复杂度事实上是 $O((n-a)\log n)$，其中 $a$ 为最大数组的大小）。方便起见，我们一般只维护凸包的上轮廓或是下轮廓。&lt;/p>
&lt;p>最值卷积听起来很让人激动。类似“给定若干个特定重量和价值的物品，求总重量为特定值时物品的最大总价值”一类的背包问题难道就这样轻松解决了吗？我们把每单个物品都视作一条线段（在我们的理论中，线段也属于凸包），对这些凸包进行合并，不就得到最终答案对应的凸包了吗？事实并非如此美好。因为最终求到的结果中，某些答案对应的点不在凸包的顶点上，而在凸包的边上；而由于单个物品只能取到线段的两个端点而不能取到线段上的非端点（即物品只可取 0 个或 1 个而不能取 0.5 个），最终我们得到的凸包上的非顶点也是不能取的。也就是说，这样求出的凸包，只有顶点对应了的重量求出的是正确答案，其余均求得偏大了。换句话讲，闵可夫斯基和本质上求的是所有可行解的凸包，这些可行解有的在凸包内部，有的在凸包顶点上；只有那些恰好在顶点上的最优解被得到了，而那些不在顶点上的最优解，我们只知道其在这个凸包的范围内，而不知其具体值。&lt;/p>
&lt;p>为了保证我们能得到所有最优解，必须确保最优解具有凸性，从而它们都在凸包顶点上。最优解是否具有凸性，是能否使用闵可夫斯基和的重要依据。&lt;/p></description></item><item><title>最小生成树上路径为最小瓶颈路的证明</title><link>https://www.flandre.love/zh/posts/proof_mbp_mst/</link><pubDate>Mon, 01 Aug 2022 16:01:25 +0800</pubDate><guid>https://www.flandre.love/zh/posts/proof_mbp_mst/</guid><description>&lt;p>对于无向图 $G$，$x$ 到 $y$ 的最小瓶颈路定义为它们间所有简单路径中最大边权最小的路径。显然，$x$ 到 $y$ 的最小瓶颈路不一定只有唯一一条。&lt;/p>
&lt;p>一个广为人知的结论是，$G$ 的一个最小生成树上 $x$ 到 $y$ 的路径是它们间的一个最小瓶颈路。下面给出两个证明。&lt;/p>
&lt;h2 id="从构造方法证明">从构造方法证明&lt;/h2>
&lt;p>假定我们的最小生成树由 Kruskal 算法构造。&lt;/p>
&lt;p>设 $x$ 到 $y$ 最小瓶颈路上的最大边权为 $m$。由于 $x$ 到 $y$ 最小瓶颈路上的最大边权为 $m$，一定可以仅通过边权小于等于 $m$ 的边使 $x$ 和 $y$ 联通，则在 Kruskal 算法仅处理完边权小于等于 $m$ 的边时，$x$ 和 $y$ 已在生成树中联通，即最小生成树中 $x$ 到 $y$ 的路径上的最大边权小于等于 $m$。&lt;/p>
&lt;p>类似地，也可以说明 Prim 算法构造的最小生成树具有该性质。这样不能证明其他最小生成树也具有性质。&lt;/p>
&lt;h2 id="反证法">反证法&lt;/h2>
&lt;p>设 $x$ 到 $y$ 最小瓶颈路上的最大边权为 $m$。假设最小生成树 $T = (V, E)$ 上 $x$ 到 $y$ 的路径上存在边权大于 $m$ 的边，则我们去除 $T$ 中所有边权大于 $m$ 的边 (记作 $V_m$)，$T$ 中剩余的边与顶点形成的图 $T_m = (\complement_VV_m, E)$ 中含超过一个连通块。&lt;/p>
&lt;p>由于 $x$ 到 $y$ 存在一条所有边的边权都不超过 $m$ 的路径，一定可以加入 $p$ 条边权不大于 $m$ 的边，使得包含 $x$ 所在连通块和 $y$ 所在连通块的一系列共 $p + 1$ 个连通块连通。之后再加入 $|V_m| - p$ 个 $V_m$ 中的边，即可形成一个新的生成树 $T^\prime$。&lt;/p>
&lt;p>比较 $T$ 和 $T^\prime$，发现 $T^\prime$ 以一些边权不大于 $m$ 的边替换了 $T$ 中边权大于 $m$ 的边，故 $T^\prime$ 的边权和比 $T$ 的更小，$T$ 不是最小生成树，与假设矛盾。&lt;/p></description></item><item><title>Boruvka 算法</title><link>https://www.flandre.love/zh/posts/boruvka/</link><pubDate>Fri, 26 Mar 2021 11:38:23 +0800</pubDate><guid>https://www.flandre.love/zh/posts/boruvka/</guid><description>&lt;p>Borůvka 算法是一种基于贪心的最小生成树算法，它比 Prim 算法和 Kruskal 算法更加古老。在 Borůvka 算法的基础上，已经发展出了&lt;a href="https://www.flandre.love/files/a-randomized-linear-time-algorithm-to-find-mst.pdf">线性的最小生成树算法&lt;/a>。&lt;/p>
&lt;p>Borůvka 算法的思想是：每次迭代，选取每一个连通块中最小的连向另一个连通块的边，将其加入最小生成树。其过程如下伪代码所示：&lt;/p>
&lt;p>$$
\begin{array}{ll}
1 &amp;amp; \textbf{Input.}\text{ Edge set }E\text{ and vertex set }V\text{ of the graph}\newline
2 &amp;amp; \textbf{Output.}\text{ A minimum spanning tree of the graph}\newline
3 &amp;amp; \textbf{Method.}\newline
4 &amp;amp; \textbf{Function}\text{ Borůvka(void)}\newline
5 &amp;amp; \qquad S\text{ is a graph of vertex set }V\text{ and empty edge set}\newline
6 &amp;amp; \qquad\textbf{while}\text{ the count of connected components in }S&amp;gt;1\newline
7 &amp;amp; \qquad\qquad T\text{ is an empty set}\newline
8 &amp;amp; \qquad\qquad\textbf{for}\text{ each connected component }C\text{ in }S\newline
9 &amp;amp; \qquad\qquad\qquad\text{edge }(u,v)\text{ is the minimum edge that connects }C\text{ and another component}\newline
10 &amp;amp; \qquad\qquad\qquad\textbf{if }(u,v)\notin T\newline
11 &amp;amp; \qquad\qquad\qquad\qquad T\gets T+(u,v)\newline
12 &amp;amp; \qquad\qquad\textbf{for}\text{ each edge }(u,v)\in T\newline
13 &amp;amp; \qquad\qquad\qquad S\gets S+(u,v)\newline
14 &amp;amp; \qquad\textbf{return }S\newline
15 &amp;amp; \textbf{End}\newline
16 &amp;amp; \textbf{return }\text{Borůvka()}
\end{array}
$$&lt;/p>
&lt;p>对于每次迭代，迭代后的每个连通块至少包含两个迭代前的连通块，故连通块总数至少减少一半，迭代次数为对数级别。&lt;/p>
&lt;p>可以发现，对于每次迭代，若 $T$ 中的某些边可以连接若干个连通块形成环，则该环上属于 $T$ 的所有边的边权一定相等。因此只要确保所有边权互不相等我们就可断定 Borůvka 算法必然不会成环。&lt;/p>
&lt;p>实际情况中可能会出现一些边边权相等的情况，但我们可以给边随意分配一个第二关键字，或是用并查集排除形成环的边。因此，Borůvka 算法可以用于存在边权相同的图。&lt;/p></description></item></channel></rss>